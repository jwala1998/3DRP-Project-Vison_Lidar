{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN8himoe/oVQRqBXCmBInBU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6tBwuC0_CVLk","executionInfo":{"status":"ok","timestamp":1701876560396,"user_tz":300,"elapsed":1317,"user":{"displayName":"Jwalandhar Girnar","userId":"07935721020492465045"}},"outputId":"783f771b-a15e-4af5-bb4e-ab4d2a34e107"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import struct\n","import datetime as dt\n","import glob\n","import os\n","from collections import namedtuple\n","import matplotlib.image as mpimg\n","import cv2\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from mpl_toolkits.mplot3d import Axes3D\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["from sklearn.metrics import average_precision_score\n","\n","# true_labels: true labels (1 for positive, 0 for negative)\n","# predicted_scores: confidence scores predicted by the model\n","true_path= os.path.join('drive', 'My Drive', '3DRP project/runs/gt_image_2')\n","true=[f for f in os.listdir(true_path) if f.endswith(\".png\")]\n","true.sort()\n","\n","predicted_path= os.path.join('drive', 'My Drive', '3DRP project/runs/30epoch_only_rgb_road')\n","predicted=[f for f in os.listdir(predicted_path) if f.endswith(\".png\")]\n","predicted.sort()\n","\n","true_labels=[]\n","predicted_scores=[]\n","\n","\n","for lidar_file, image_file in zip(true, predicted):\n","    # Construct the full paths\n","    tru_pth= os.path.join(true_path, lidar_file)\n","    pred_pth = os.path.join(predicted_path, image_file)\n","    # file_path_calib = os.path.join(calib_path, calib_file)\n","\n","    tru1= cv2.imread(tru_pth)\n","    pred1= cv2.imread(pred_pth)\n","\n","    # tru1.flatten()\n","    # pred1.flatten()\n","    tru1= tru1[:,:,0:]\n","    pred1= tru1[:,:,0:]\n","\n","\n","    true_labels.append(tru1)\n","    predicted_scores.append(pred1)\n","    average_precision = average_precision_score(tru1, pred1)\n","    print(f'Average Precision: {average_precision}')\n","\n","    # exit()\n","\n","true_labels=np.array(true_labels)\n","predicted_scores=np.array(predicted_scores)\n","\n","\n","# average_precision = average_precision_score(true_labels, predicted_scores)\n","# average_precision = average_precision_score(tru1, pred1)\n","\n","\n","print(f'Average Precision: {average_precision}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"HNaBnTVMqpdx","executionInfo":{"status":"error","timestamp":1701876692512,"user_tz":300,"elapsed":251,"user":{"displayName":"Jwalandhar Girnar","userId":"07935721020492465045"}},"outputId":"17e9079d-44e6-43e7-fc45-828cd24d6c79"},"execution_count":3,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-77a0514e3051>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtrue_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtru1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mpredicted_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0maverage_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtru1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Average Precision: {average_precision}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0m_binary_uninterpolated_average_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     )\n\u001b[0;32m--> 234\u001b[0;31m     return _average_binary_score(\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0maverage_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: unknown format is not supported"]}]},{"cell_type":"code","source":["    def get_velo_scans(bin_path):\n","        obj = np.fromfile(bin_path, dtype=np.float32).reshape(-1, 4)\n","        return obj"],"metadata":{"id":"_P0xpClVCcPD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"Read in a calibration file and parse into a dictionary.\"\"\"\n","def read_calib_file(filepath):\n","    data = {}\n","\n","    with open(filepath, 'r') as f:\n","        for line in f.readlines():\n","            key, value = line.split(':', 1)\n","            # The only non-float values in these files are dates, which\n","            # we don't care about anyway\n","            try:\n","                data[key] = np.array([float(x) for x in value.split()])\n","            except ValueError:\n","                pass\n","\n","    return data\n","\n","\"\"\"\n","  Filter camera angles for KiTTI Datasets\n","\"\"\"\n","def filter_by_camera_angle(pc):\n","    bool_in = np.logical_and((pc[:, 1] < pc[:, 0] - 0.27), (-pc[:, 1] < pc[:, 0] - 0.27))\n","    \"\"\"\n","    /*\n","      * @brief KiTTI Velodyne Coordinate\n","      *          |x(forward)\n","      *      C   |   D\n","      *          |\n","      *  y---------------\n","      *          |\n","      *      B   |   A\n","      */\n","    \"\"\"\n","    # bool_in = np.where(pc[:, 0] > 0)\n","    return pc[bool_in]"],"metadata":{"id":"sGQ1LG-XChJT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from matplotlib import cm\n","\n","class Color(object):\n","    jet = None\n","\n","    \"\"\"\n","      https://github.com/ros-visualization/rviz/blob/kinetic-devel/src/rviz/default_plugin/point_cloud_transformers.cpp\n","      :return\n","        Rainbow color (rgb8) from val in [0., 1.]\n","    \"\"\"\n","    @staticmethod\n","    def get_rainbow_color(val, min_val=0., diff=255):\n","        value = 1.0 - (val - min_val)\n","        # restrict value between 0 and 1\n","        value = max(value, 0.)\n","        value = min(value, 1.)\n","\n","        h = value * 5.0 + 1.0\n","        i = int(h)\n","        f = h - i\n","        # if i is even\n","        if not i&1:\n","            f = 1 - f\n","        n = int((1 - f)*diff)\n","        bgr = [0]*3\n","        if i <= 1:\n","            bgr[2] = n; bgr[1] = 0; bgr[0] = 255\n","        elif i == 2:\n","            bgr[2] = 0; bgr[1] = n; bgr[0] = 255\n","        elif i == 3:\n","            bgr[2] = 0; bgr[1] = 255; bgr[0] = n\n","        elif i == 4:\n","            bgr[2] = n; bgr[1] = 255; bgr[0] = 0\n","        elif i >= 5:\n","            bgr[2] = 255; bgr[1] = n; bgr[0] = 0\n","        # print bgr\n","        return bgr\n","\n","\n","    def get_heat_color(point):\n","\n","        rgb = [0]*3\n","\n","        if point[2] <= -1.67:\n","            rgb[2] = 255; rgb[1] = 150-(point[2]/-2)*150; rgb[0] = 0\n","\n","        elif  point[2] <= -1.63 and point[2] > -1.67:\n","            rgb[2] = 255; rgb[1] = 125; rgb[0] = 0\n","        elif  point[2] <= -1.6 and point[2] > -1.63:\n","            rgb[2] = 255; rgb[1] = 200; rgb[0] = 0\n","        elif  point[2] <= -1.55 and point[2] > -1.6:\n","            rgb[2] = 255; rgb[1] = 255; rgb[0] = 0\n","        elif  point[2] <= -1.4 and point[2] > -1.55:\n","            rgb[2] = 0; rgb[1] = 255; rgb[0] = 0\n","        elif  point[2] <= -1.2 and point[2] > -1.4:\n","            rgb[2] = 0; rgb[1] = 255; rgb[0] = 125\n","        elif  point[2] <= 0 and point[2] > -1.2:\n","            rgb[2] = 0; rgb[1] = 75; rgb[0] = 255\n","        else:\n","            rgb[2] = 0; rgb[1] = 0; rgb[0] = 255\n","\n","        return rgb\n"],"metadata":{"id":"2ASXLH9UCpHs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","  1. Color Point Cloud from RGB Image\n","  2. Project Point Cloud into RGB Image for depth\n","  3. Also apply to Gray Image\n","\"\"\"\n","def lidar_camera_fusion(point_cloud, image, T_velo_cam, P_velo_image):\n","    image_size = image.shape\n","\n","    is_gray = len(image_size) < 3\n","    if is_gray:\n","        print(\"LiDAR Gray-Image fusing...\")\n","    else:\n","        print(\"LiDAR RGB-Image fusing...\")\n","\n","    image_depth = image.copy()\n","\n","    # XYZRGB point cloud\n","    #modify these for old\n","    pc_rgb = np.zeros((point_cloud.shape[0], 4), dtype=np.float32)\n","    pc_rgb_6 = np.zeros((point_cloud.shape[0], 6), dtype=np.float32)\n","\n","    pc_rgb[:, :3] = point_cloud[:, :3]\n","    pc_rgb_6[:, :3] = point_cloud[:, :3]\n","\n","\n","    xyz = point_cloud.copy()\n","    xyz[:,3] = 1.0\n","    # project into image\n","    velo_img = np.dot(P_velo_image, xyz.T).T\n","    # normalize homogeneous coordinates\n","    velo_img = np.true_divide(velo_img[:,:2], velo_img[:,[-1]])\n","    velo_img = np.round(velo_img).astype(np.uint16)\n","\n","    # compute depth in Camera coordinate\n","#         pc_img = np.dot(T_velo_cam, xyz.T).T\n","#         depth = np.sqrt(np.square(pc_img[:, 0]) + np.square(pc_img[:, 1]) + np.square(pc_img[:, 2]))\n","#         depth_min = min(depth)\n","#         depth_max = max(depth)\n","#         depth = depth / (depth_max - depth_min)\n","\n","    height = point_cloud[:,2]\n","    height_min = min(height)\n","    height_max = min(height)\n","    height = height / height_max\n","\n","\n","    if is_gray:\n","        for pt in range(0, velo_img.shape[0]):\n","            row_idx = velo_img[pt][1]\n","            col_idx = velo_img[pt][0]\n","\n","            if (row_idx >= 0 and row_idx < image_size[0]) \\\n","                    and (col_idx >= 0 and col_idx < image_size[1]):\n","                # assign image color to point cloud\n","                color =   (image[row_idx][col_idx] << 16) \\\n","                        | (image[row_idx][col_idx] << 8) \\\n","                        | image[row_idx][col_idx]\n","                pc_rgb[pt, 3] = color\n","\n","                # assign point cloud to image pixel\n","                cv2.circle(image_depth, (col_idx,row_idx), 1, depth[pt] * 255, thickness=-1)\n","    else:\n","        for pt in range(0, velo_img.shape[0]):\n","            row_idx = velo_img[pt][1]\n","            col_idx = velo_img[pt][0]\n","\n","            if (row_idx >= 0 and row_idx < image_size[0]) \\\n","                    and (col_idx >= 0 and col_idx < image_size[1]):\n","                # assign image color to point cloud\n","#                     color =   (image[row_idx][col_idx][2] << 16) \\\n","#                               | (image[row_idx][col_idx][1] << 8) \\\n","#                               | image[row_idx][col_idx][0]\n","                #modify these for old values\n","                color = image[row_idx][col_idx][2]\n","                pc_rgb[pt, 3] = color\n","                colors = image[row_idx][col_idx][:]\n","                pc_rgb_6[pt, 3:] = colors\n","\n","                # assign point cloud to image pixel\n","                # use rainbow color band\n","                cv_color = Color.get_heat_color(point_cloud[pt])\n","#                     cv_color = Color.get_rainbow_color(height[pt])\n","                # image_depth[row_idx][col_idx] = cv_color\n","                cv2.circle(image_depth, (col_idx,row_idx), 1, cv_color, thickness=-1)\n","\n","    return pc_rgb, image_depth, pc_rgb_6, velo_img"],"metadata":{"id":"aPj3BjsJCv59"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = \"3DRP project/3d perp/Project/data_toad_velodyne/training/velodyne/\"\n","Lidar_path = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","\n","\n","# Your text data\n","GOOGLE_DRIVE_PATH_AF = \"3DRP project/3d perp/Project/data_road/training/calib\"\n","calib_path= os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AF)\n","\n","\n","GOOGLE_DRIVE_PATH_AFTER = \"3DRP project/3d perp/Project/data_road/training/image_2\"\n","cam_path= os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER)\n","\n","\n","GOOGLE_DRIVE_PATH_1 = \"3DRP project/csvs/pc_rgb\"\n","GOOGLE_DRIVE_PATH_2 = \"3DRP project/csvs/pc_rgb_6\"\n","GOOGLE_DRIVE_PATH_3 = \"3DRP project/Project/fused_data/npy\"\n","GOOGLE_DRIVE_PATH_0 = \"3DRP project/Project/fused_data/png\"\n","\n","\n","\n","\n","# List all files in each directory\n","lidar_files = [f for f in os.listdir(Lidar_path) if f.endswith(\".bin\")]\n","image_files = [f for f in os.listdir(cam_path) if f.endswith(\".png\")]\n","calib_files= [f for f in os.listdir(calib_path) if f.endswith(\".txt\")]\n","\n","# Sort the files to ensure that files with similar names correspond to each other\n","lidar_files.sort()\n","image_files.sort()\n","calib_files.sort()\n","\n","\n","\n","# Iterate over the files with similar names\n","for lidar_file, image_file, calib_file in zip(lidar_files, image_files, calib_files):\n","    # Construct the full paths\n","    filename_pc= os.path.join(Lidar_path, lidar_file)\n","    img_path_png = os.path.join(cam_path, image_file)\n","    file_path_calib = os.path.join(calib_path, calib_file)\n","\n","\n","    pc = get_velo_scans(filename_pc)\n","    # print(pc.shape)\n","    pc = filter_by_camera_angle(pc)\n","\n","\n","        # Open the file in read mode ('r')\n","    with open(file_path_calib, 'r') as file:\n","        # Read the contents of the file\n","        file_contents = file.read()\n","\n","    # Now, file_contents contains the contents of the text file\n","    # print(file_contents)\n","\n","    text_data= file_contents\n","\n","\n","    # Extract P1 data using regular expression\n","    pattern = re.compile(r'P2: (.+)')\n","    match = pattern.search(text_data)\n","\n","    if match:\n","        p1_data_str = match.group(1)\n","        p2_data = np.fromstring(p1_data_str, sep=' ')\n","        # print(\"P1 Data as NumPy array:\", p2_data_np)\n","    else:\n","        print(\"P1 Data not found.\")\n","\n","\n","    # Extract Rect data using regular expression\n","    pattern = re.compile(r'R0_rect: (.+)')\n","    match = pattern.search(text_data)\n","\n","    if match:\n","        p1_data_str = match.group(1)\n","        rect_data = np.fromstring(p1_data_str, sep=' ')\n","        # print(\"Rect Data as NumPy array:\", p1_data_np)\n","    else:\n","        print(\"Rect Data not found.\")\n","\n","\n","    # Extract Tr_velo_to_cam data using regular expression\n","    pattern = re.compile(r'Tr_velo_to_cam: (.+)')\n","    match = pattern.search(text_data)\n","\n","    if match:\n","        p1_data_str = match.group(1)\n","        velo_cam_data= np.fromstring(p1_data_str, sep=' ')\n","        # print(\"velo_cam Data as NumPy array:\", p1_data_np)\n","    else:\n","        print(\"velo_cam Data not found.\")\n","\n","\n","    # To project a 3D point x in reference camera coordinates to a point y on the i'th image plane,\n","    # the rectifying rotation matrix of the reference camera: R_rect_00 must be considered as well.\n","    R_rect_00 = np.zeros((4, 4))\n","\n","    R_rect_00[:3,:3] = rect_data.reshape(-1, 3)\n","\n","\n","    R_rect_00[3,3] = 1.  #instead can divide by the end term\n","\n","    P_rect_02 = np.zeros((3, 4))\n","\n","    P_rect_02 = p2_data.reshape(-1, 4)\n","\n","\n","    vel2cam0 = np.zeros((4, 4))\n","\n","    vel2cam0[:3,:4] = velo_cam_data.reshape(-1, 4)\n","\n","\n","    vel2cam0[3,3] = 1.   #instead can divide by the last term\n","    vel2cam0 = vel2cam0/vel2cam0[3,3]   #instead can divide by the last term\n","\n","\n","    T_velo_to_cam = np.dot(R_rect_00, vel2cam0)\n","\n","    P_velo_to_img = np.dot(P_rect_02, np.dot(R_rect_00, vel2cam0))\n","\n","    image = cv2.imread(img_path_png)\n","\n","    # XYZRGB point cloud and depth image\n","    pc_rgb, image_depth, pc_rgb_6, velo_image = lidar_camera_fusion(pc, image, T_velo_to_cam, P_velo_to_img)\n","\n","    # print(pc_rgb[300, :])\n","    out_path= os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_0,image_file)\n","    cv2.imwrite(out_path, pc_rgb)\n","    # cv2.imwrite(out_path, image_depth)\n","\n","\n","    name= calib_file.replace('txt','npy')\n","    out_path_rgb= os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_1,name)\n","    out_path_rgb_6= os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_2,name)\n","    out_path_fused= os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_3,name)\n","\n","\n","    # Example headers\n","    header_rgb = ['X', 'Y', 'Z', 'Color']\n","    header_rgb_6 = ['X', 'Y', 'Z', 'R', 'G', 'B']\n","\n","\n","    # Save the NumPy array to a CSV file with headers\n","    # np.savetxt(out_path_rgb, pc_rgb, delimiter=',', header=','.join(header_rgb), comments='')\n","    # np.savetxt(out_path_rgb_6, pc_rgb_6, delimiter=',', header=','.join(header_rgb_6), comments='')\n","\n","    pcd=pc[:,:3]\n","    data= np.hstack((velo_image,pcd))\n","    y_lim, x_lim,_=image.shape\n","    #filter out non valid pixles\n","    data = data[(data[:, 0] >= 0) & (data[:, 0] < x_lim) & (data[:, 1] >= 0) & (data[:, 1] < y_lim)]\n","\n","    final_data=np.zeros(((y_lim,x_lim,6)))\n","    final_data[:,:,3:6]=image\n","    coords= data[:,0:2]  #[x,y]\n","    coords=coords.astype(int)\n","    xyz= data[:,2:5]\n","\n","    final_data[coords[:,1],coords[:,0],0:3]= xyz\n","    np.save(out_path_fused, final_data)\n","    # np.savetxt(out_path_fused, finalnow how do i train these models with input as _data, delimiter=',', header=','.join(header_rgb_6), comments='')\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"udBT2-_hC3rC","executionInfo":{"status":"ok","timestamp":1701801681649,"user_tz":300,"elapsed":211715,"user":{"displayName":"Jwalandhar Girnar","userId":"07935721020492465045"}},"outputId":"48667a74-6f70-4826-941f-0c44b7137b43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n","LiDAR RGB-Image fusing...\n"]}]}]}